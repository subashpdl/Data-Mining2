{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Training with all models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import autokeras as ak\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils import resample,shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neural_network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to test the predictions\n",
    "\n",
    "def count_points(pred, gold):\n",
    "    df = pd.merge(pred, gold, on=['userID', 'itemID'], suffixes=('_pred', '_gold'))\n",
    "    df['points'] = df.apply(_compute_points_for_row, axis=1)\n",
    "    return df['points'].sum()\n",
    "\n",
    "def _compute_points_for_row(row):\n",
    "    y_pred, y_gold = row.prediction_pred, row.prediction_gold\n",
    "    if y_pred == y_gold:\n",
    "        # one point if \"no order\" (0) is predicted correctly; three points if order week is predicted correctly\n",
    "        return 1 if y_pred == 0 else 3\n",
    "    # one point if order is predicted correctly (but not the correct week), otherwise zero points\n",
    "    return 1 if (y_pred > 0 and y_gold > 0) else 0\n",
    "\n",
    "def preprocessData(df):\n",
    "    labels = df[\"label\"] # generating a label dataset\n",
    "    data = df.drop(['label'], axis = 1) #dropping label\n",
    "    data = df.drop(['order'], axis = 1) #dropping order\n",
    "    data = df.drop(['date'], axis = 1) #dropping date\n",
    "    \n",
    "    enc = OneHotEncoder(handle_unknown='ignore') #onehotencoder\n",
    "    cols = [\"feature_1\", \"feature_2\", \"feature_4\"] #columns to onehot encode\n",
    "    enc.fit(data[cols])\n",
    "    encoder_df = pd.DataFrame(enc.transform(data[cols]).toarray()) #encoding\n",
    "    data = data[[\"userID\", \"itemID\", \"brand\", \"feature_3\", \"feature_5\" \n",
    "                 ,]].join(encoder_df) #merging\n",
    "                 #\"date_of_month\", \"total_purchase_times\",\"purchased_frequency\",\"category\", \"weekday\",]].join(encoder_df) #merging\n",
    "    \n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    #lenc = enc.fit(np_labels)\n",
    "    lb = lb.fit(labels.to_numpy())\n",
    "    labels_enc = lb.transform(labels.to_numpy())\n",
    "    \n",
    "    return labels_enc, data, lb, enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767131\n",
      "767131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15215</td>\n",
       "      <td>19979</td>\n",
       "      <td>724</td>\n",
       "      <td>503</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39567</td>\n",
       "      <td>19979</td>\n",
       "      <td>724</td>\n",
       "      <td>503</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12385</td>\n",
       "      <td>19979</td>\n",
       "      <td>724</td>\n",
       "      <td>503</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27356</td>\n",
       "      <td>19979</td>\n",
       "      <td>724</td>\n",
       "      <td>503</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26707</td>\n",
       "      <td>19979</td>\n",
       "      <td>724</td>\n",
       "      <td>503</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  brand  feature_3  feature_5    0    1    2    3    4  ...  \\\n",
       "0   15215   19979    724        503         17  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1   39567   19979    724        503         17  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2   12385   19979    724        503         17  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3   27356   19979    724        503         17  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4   26707   19979    724        503         17  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "    12   13   14   15   16   17   18   19   20   21  \n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_dec = pd.read_csv(\"train_bef_dec.csv\")\n",
    "train_dec = pd.read_csv(\"orders_before_dec_labeled.csv\", sep = \",\")\n",
    "print(len(train_dec))\n",
    "df_items = pd.read_csv(\"items.csv\", sep = \"|\") #items\n",
    "\n",
    "train_dec = pd.merge(train_dec, df_items, on=\"itemID\") #merging the dataset on itemID \n",
    "\n",
    "print(len(train_dec))\n",
    "\n",
    "y_train, x_train, binarizer, enc = preprocessData(train_dec)\n",
    "\n",
    "x_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113478\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m test_dec \u001b[38;5;241m=\u001b[39m test_dec\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_dec))\n\u001b[1;32m----> 4\u001b[0m y_test, x_test, binarizer \u001b[38;5;241m=\u001b[39m preprocessData(train_dec)\n\u001b[0;32m      6\u001b[0m x_train\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "test_dec = pd.read_csv(\"test_dec.csv\")\n",
    "test_dec = test_dec.sort_values(by=[\"userID\"])\n",
    "print(len(test_dec))\n",
    "y_test, x_test, binarizer = preprocessData(train_dec)\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21817\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>order</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>category</th>\n",
       "      <th>weekday</th>\n",
       "      <th>date_of_month</th>\n",
       "      <th>total_purchase_times</th>\n",
       "      <th>purchased_frequency</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020/12/11</td>\n",
       "      <td>0</td>\n",
       "      <td>20664</td>\n",
       "      <td>1</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2346</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020/12/11</td>\n",
       "      <td>17516</td>\n",
       "      <td>3148</td>\n",
       "      <td>1</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2346</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020/12/11</td>\n",
       "      <td>0</td>\n",
       "      <td>28231</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>468</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>3898</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020/12/30</td>\n",
       "      <td>0</td>\n",
       "      <td>28231</td>\n",
       "      <td>5</td>\n",
       "      <td>1496</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>3898</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>19.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020/12/28</td>\n",
       "      <td>0</td>\n",
       "      <td>28231</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>3898</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>3.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  userID  itemID  order  brand  feature_1  feature_2  feature_3  \\\n",
       "0  2020/12/11       0   20664      1    408          4          0        284   \n",
       "1  2020/12/11   17516    3148      1    408          4          0        284   \n",
       "2  2020/12/11       0   28231      1    193          4          3        468   \n",
       "3  2020/12/30       0   28231      5   1496         10          0        348   \n",
       "4  2020/12/28       0   28231      1    186          4          0         28   \n",
       "\n",
       "   feature_4  feature_5  category  weekday  date_of_month  \\\n",
       "0          0         66      2346        4             11   \n",
       "1          0         66      2346        4             11   \n",
       "2          3        108      3898        4             11   \n",
       "3          0         95      3898        2             30   \n",
       "4          0         81      3898        0             28   \n",
       "\n",
       "   total_purchase_times  purchased_frequency  prediction  Unnamed: 16  \\\n",
       "0                    14                 0.71         NaN          NaN   \n",
       "1                    14                 0.71         NaN          NaN   \n",
       "2                    14                 0.19         NaN          NaN   \n",
       "3                    49                19.65         NaN          NaN   \n",
       "4                    33                 3.90         NaN          NaN   \n",
       "\n",
       "   Unnamed: 17  Unnamed: 18  \n",
       "0          NaN          NaN  \n",
       "1          NaN          NaN  \n",
       "2          NaN          NaN  \n",
       "3          NaN          NaN  \n",
       "4          NaN          NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dec = pd.read_csv(\"prediction_dec.csv\", sep = \",\")\n",
    "print(len(pred_dec))\n",
    "pred_dec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20664</td>\n",
       "      <td>408</td>\n",
       "      <td>284</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23363</td>\n",
       "      <td>20664</td>\n",
       "      <td>408</td>\n",
       "      <td>284</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28231</td>\n",
       "      <td>193</td>\n",
       "      <td>468</td>\n",
       "      <td>108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2690</td>\n",
       "      <td>406</td>\n",
       "      <td>491</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1299</td>\n",
       "      <td>1056</td>\n",
       "      <td>474</td>\n",
       "      <td>108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>46049</td>\n",
       "      <td>17984</td>\n",
       "      <td>449</td>\n",
       "      <td>207</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>46069</td>\n",
       "      <td>29992</td>\n",
       "      <td>280</td>\n",
       "      <td>484</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9742</th>\n",
       "      <td>46117</td>\n",
       "      <td>8847</td>\n",
       "      <td>143</td>\n",
       "      <td>46</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9743</th>\n",
       "      <td>46124</td>\n",
       "      <td>19677</td>\n",
       "      <td>1006</td>\n",
       "      <td>491</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>46127</td>\n",
       "      <td>7963</td>\n",
       "      <td>1111</td>\n",
       "      <td>485</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9745 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  itemID  brand  feature_3  feature_5    0    1    2    3    4  \\\n",
       "0          0   20664    408        284         66  0.0  0.0  0.0  0.0  0.0   \n",
       "1      23363   20664    408        284         66  0.0  0.0  0.0  0.0  0.0   \n",
       "2          0   28231    193        468        108  0.0  0.0  0.0  0.0  0.0   \n",
       "3         13    2690    406        491         66  0.0  0.0  0.0  0.0  0.0   \n",
       "4         15    1299   1056        474        108  0.0  0.0  0.0  0.0  0.0   \n",
       "...      ...     ...    ...        ...        ...  ...  ...  ...  ...  ...   \n",
       "9740   46049   17984    449        207         45  0.0  0.0  0.0  0.0  0.0   \n",
       "9741   46069   29992    280        484         44  0.0  0.0  0.0  0.0  0.0   \n",
       "9742   46117    8847    143         46         69  0.0  0.0  0.0  0.0  0.0   \n",
       "9743   46124   19677   1006        491        154  0.0  0.0  0.0  0.0  0.0   \n",
       "9744   46127    7963   1111        485        154  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      ...   12   13   14   15   16   17   18   19   20   21  \n",
       "0     ...  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "1     ...  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2     ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3     ...  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "4     ...  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "9740  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "9741  ...  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "9742  ...  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "9743  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "9744  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[9745 rows x 27 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'submission_dec'\n",
    "\n",
    "df_submission = pd.read_csv( name+\".csv\", sep = \"|\")\n",
    "\n",
    "result_pred = pd.merge(df_submission, df_items, on=\"itemID\")\n",
    "\n",
    "result_pred = result_pred.drop(['categories'], axis = 1)\n",
    "data = result_pred.drop(['prediction'], axis = 1)\n",
    "cols = [\"feature_1\", \"feature_2\", \"feature_4\"]\n",
    "\n",
    "encoder_df = pd.DataFrame(enc.transform(data[cols]).toarray())\n",
    "submission = data[[\"userID\",\"itemID\", \"brand\", \"feature_3\", \"feature_5\"]].join(encoder_df)\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knabp_000\\anaconda3\\envs\\Envi\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 2\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "x_train, y_train=  sm.fit_resample(x_train, y_train)\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(x_train, y_train, test_size=0.5, random_state=42)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "print(len(X_train.shape), len(X_test.shape), len(X_val.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr = X_train.to_numpy()\n",
    "X_val_arr = X_val.to_numpy()\n",
    "X_test_arr = X_test.to_numpy()\n",
    "\n",
    "y_val_n = binarizer.inverse_transform(y_val)\n",
    "y_train_n = binarizer.inverse_transform(y_train)\n",
    "y_test_n = binarizer.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309119"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 07m 20s]\n",
      "val_loss: 1.3265565633773804\n",
      "\n",
      "Best val_loss So Far: 1.3265565633773804\n",
      "Total elapsed time: 00h 07m 20s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 29.1503 - accuracy: 0.2684 - val_loss: 12.3469 - val_accuracy: 0.3124\n",
      "Epoch 2/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 17.1687 - accuracy: 0.2974 - val_loss: 22.6746 - val_accuracy: 0.2111\n",
      "Epoch 3/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 12.4667 - accuracy: 0.3087 - val_loss: 11.5506 - val_accuracy: 0.3205\n",
      "Epoch 4/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 9.4833 - accuracy: 0.3118 - val_loss: 6.3262 - val_accuracy: 0.3243\n",
      "Epoch 5/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 6.6722 - accuracy: 0.3175 - val_loss: 7.4882 - val_accuracy: 0.2528\n",
      "Epoch 6/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 4.6429 - accuracy: 0.3223 - val_loss: 2.8163 - val_accuracy: 0.3530\n",
      "Epoch 7/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 3.2119 - accuracy: 0.3301 - val_loss: 1.7345 - val_accuracy: 0.3266\n",
      "Epoch 8/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 2.1339 - accuracy: 0.3412 - val_loss: 1.8898 - val_accuracy: 0.3618\n",
      "Epoch 9/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.6460 - accuracy: 0.3506 - val_loss: 1.4298 - val_accuracy: 0.3615\n",
      "Epoch 10/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.4404 - accuracy: 0.3610 - val_loss: 1.4067 - val_accuracy: 0.3565\n",
      "Epoch 11/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3789 - accuracy: 0.3672 - val_loss: 1.3628 - val_accuracy: 0.3628\n",
      "Epoch 12/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3556 - accuracy: 0.3706 - val_loss: 1.3535 - val_accuracy: 0.3612\n",
      "Epoch 13/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3502 - accuracy: 0.3720 - val_loss: 1.3664 - val_accuracy: 0.3712\n",
      "Epoch 14/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3489 - accuracy: 0.3718 - val_loss: 1.3527 - val_accuracy: 0.3738\n",
      "Epoch 15/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3427 - accuracy: 0.3720 - val_loss: 1.3592 - val_accuracy: 0.3637\n",
      "Epoch 16/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3384 - accuracy: 0.3736 - val_loss: 1.3515 - val_accuracy: 0.3681\n",
      "Epoch 17/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3336 - accuracy: 0.3758 - val_loss: 1.3399 - val_accuracy: 0.3676\n",
      "Epoch 18/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3313 - accuracy: 0.3778 - val_loss: 1.3277 - val_accuracy: 0.3806\n",
      "Epoch 19/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3272 - accuracy: 0.3797 - val_loss: 1.3333 - val_accuracy: 0.3803\n",
      "Epoch 20/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3248 - accuracy: 0.3810 - val_loss: 1.3273 - val_accuracy: 0.3808\n",
      "Epoch 21/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3231 - accuracy: 0.3821 - val_loss: 1.3239 - val_accuracy: 0.3827\n",
      "Epoch 22/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3215 - accuracy: 0.3833 - val_loss: 1.3224 - val_accuracy: 0.3829\n",
      "Epoch 23/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3187 - accuracy: 0.3841 - val_loss: 1.3216 - val_accuracy: 0.3833\n",
      "Epoch 24/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3178 - accuracy: 0.3844 - val_loss: 1.3210 - val_accuracy: 0.3821\n",
      "Epoch 25/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3169 - accuracy: 0.3847 - val_loss: 1.3190 - val_accuracy: 0.3853\n",
      "Epoch 26/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3158 - accuracy: 0.3850 - val_loss: 1.3187 - val_accuracy: 0.3844\n",
      "Epoch 27/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3153 - accuracy: 0.3857 - val_loss: 1.3220 - val_accuracy: 0.3844\n",
      "Epoch 28/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3153 - accuracy: 0.3856 - val_loss: 1.3216 - val_accuracy: 0.3844\n",
      "Epoch 29/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3141 - accuracy: 0.3855 - val_loss: 1.3198 - val_accuracy: 0.3817\n",
      "Epoch 30/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3137 - accuracy: 0.3859 - val_loss: 1.3178 - val_accuracy: 0.3859\n",
      "Epoch 31/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3131 - accuracy: 0.3859 - val_loss: 1.3174 - val_accuracy: 0.3854\n",
      "Epoch 32/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3128 - accuracy: 0.3859 - val_loss: 1.3212 - val_accuracy: 0.3841\n",
      "Epoch 33/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3123 - accuracy: 0.3863 - val_loss: 1.3242 - val_accuracy: 0.3816\n",
      "Epoch 34/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3125 - accuracy: 0.3864 - val_loss: 1.3184 - val_accuracy: 0.3850\n",
      "Epoch 35/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3123 - accuracy: 0.3864 - val_loss: 1.3207 - val_accuracy: 0.3833\n",
      "Epoch 36/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3116 - accuracy: 0.3865 - val_loss: 1.3222 - val_accuracy: 0.3847\n",
      "Epoch 37/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3113 - accuracy: 0.3866 - val_loss: 1.3200 - val_accuracy: 0.3843\n",
      "Epoch 38/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3107 - accuracy: 0.3866 - val_loss: 1.3166 - val_accuracy: 0.3855\n",
      "Epoch 39/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3101 - accuracy: 0.3869 - val_loss: 1.3166 - val_accuracy: 0.3853\n",
      "Epoch 40/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3104 - accuracy: 0.3864 - val_loss: 1.3166 - val_accuracy: 0.3864\n",
      "Epoch 41/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3105 - accuracy: 0.3868 - val_loss: 1.3191 - val_accuracy: 0.3849\n",
      "Epoch 42/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3093 - accuracy: 0.3871 - val_loss: 1.3138 - val_accuracy: 0.3852\n",
      "Epoch 43/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3089 - accuracy: 0.3866 - val_loss: 1.3155 - val_accuracy: 0.3850\n",
      "Epoch 44/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3087 - accuracy: 0.3872 - val_loss: 1.3137 - val_accuracy: 0.3860\n",
      "Epoch 45/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3087 - accuracy: 0.3870 - val_loss: 1.3154 - val_accuracy: 0.3862\n",
      "Epoch 46/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3083 - accuracy: 0.3871 - val_loss: 1.3142 - val_accuracy: 0.3860\n",
      "Epoch 47/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3083 - accuracy: 0.3869 - val_loss: 1.3159 - val_accuracy: 0.3862\n",
      "Epoch 48/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3088 - accuracy: 0.3876 - val_loss: 1.3122 - val_accuracy: 0.3877\n",
      "Epoch 49/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3075 - accuracy: 0.3877 - val_loss: 1.3149 - val_accuracy: 0.3855\n",
      "Epoch 50/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3075 - accuracy: 0.3875 - val_loss: 1.3148 - val_accuracy: 0.3866\n",
      "Epoch 51/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3069 - accuracy: 0.3875 - val_loss: 1.3160 - val_accuracy: 0.3852\n",
      "Epoch 52/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3070 - accuracy: 0.3877 - val_loss: 1.3116 - val_accuracy: 0.3864\n",
      "Epoch 53/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3067 - accuracy: 0.3877 - val_loss: 1.3167 - val_accuracy: 0.3849\n",
      "Epoch 54/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3067 - accuracy: 0.3876 - val_loss: 1.3229 - val_accuracy: 0.3856\n",
      "Epoch 55/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3059 - accuracy: 0.3878 - val_loss: 1.3144 - val_accuracy: 0.3857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3062 - accuracy: 0.3877 - val_loss: 1.3126 - val_accuracy: 0.3871\n",
      "Epoch 57/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3065 - accuracy: 0.3877 - val_loss: 1.3111 - val_accuracy: 0.3868\n",
      "Epoch 58/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3062 - accuracy: 0.3879 - val_loss: 1.3114 - val_accuracy: 0.3870\n",
      "Epoch 59/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3063 - accuracy: 0.3878 - val_loss: 1.3126 - val_accuracy: 0.3865\n",
      "Epoch 60/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3052 - accuracy: 0.3882 - val_loss: 1.3143 - val_accuracy: 0.3865\n",
      "Epoch 61/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3065 - accuracy: 0.3880 - val_loss: 1.3153 - val_accuracy: 0.3851\n",
      "Epoch 62/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3057 - accuracy: 0.3881 - val_loss: 1.3357 - val_accuracy: 0.3768\n",
      "Epoch 63/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3060 - accuracy: 0.3878 - val_loss: 1.3152 - val_accuracy: 0.3856\n",
      "Epoch 64/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3058 - accuracy: 0.3880 - val_loss: 1.3111 - val_accuracy: 0.3871\n",
      "Epoch 65/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3049 - accuracy: 0.3883 - val_loss: 1.3102 - val_accuracy: 0.3873\n",
      "Epoch 66/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3051 - accuracy: 0.3883 - val_loss: 1.3122 - val_accuracy: 0.3864\n",
      "Epoch 67/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3050 - accuracy: 0.3881 - val_loss: 1.3102 - val_accuracy: 0.3869\n",
      "Epoch 68/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3051 - accuracy: 0.3881 - val_loss: 1.3157 - val_accuracy: 0.3861\n",
      "Epoch 69/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3049 - accuracy: 0.3882 - val_loss: 1.3112 - val_accuracy: 0.3871\n",
      "Epoch 70/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3045 - accuracy: 0.3882 - val_loss: 1.3106 - val_accuracy: 0.3864\n",
      "Epoch 71/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3044 - accuracy: 0.3880 - val_loss: 1.3192 - val_accuracy: 0.3829\n",
      "Epoch 72/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3042 - accuracy: 0.3882 - val_loss: 1.3103 - val_accuracy: 0.3869\n",
      "Epoch 73/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3061 - accuracy: 0.3877 - val_loss: 1.3117 - val_accuracy: 0.3864\n",
      "Epoch 74/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3036 - accuracy: 0.3882 - val_loss: 1.3092 - val_accuracy: 0.3871\n",
      "Epoch 75/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3049 - accuracy: 0.3883 - val_loss: 1.3090 - val_accuracy: 0.3873\n",
      "Epoch 76/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3049 - accuracy: 0.3884 - val_loss: 1.3220 - val_accuracy: 0.3855\n",
      "Epoch 77/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3040 - accuracy: 0.3881 - val_loss: 1.3080 - val_accuracy: 0.3875\n",
      "Epoch 78/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3046 - accuracy: 0.3882 - val_loss: 1.3120 - val_accuracy: 0.3862\n",
      "Epoch 79/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3041 - accuracy: 0.3885 - val_loss: 1.3099 - val_accuracy: 0.3873\n",
      "Epoch 80/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3049 - accuracy: 0.3883 - val_loss: 1.3086 - val_accuracy: 0.3869\n",
      "Epoch 81/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3039 - accuracy: 0.3884 - val_loss: 1.3075 - val_accuracy: 0.3878\n",
      "Epoch 82/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3045 - accuracy: 0.3882 - val_loss: 1.3073 - val_accuracy: 0.3883\n",
      "Epoch 83/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3047 - accuracy: 0.3885 - val_loss: 1.3108 - val_accuracy: 0.3865\n",
      "Epoch 84/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3039 - accuracy: 0.3884 - val_loss: 1.3096 - val_accuracy: 0.3879\n",
      "Epoch 85/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3033 - accuracy: 0.3885 - val_loss: 1.3073 - val_accuracy: 0.3873\n",
      "Epoch 86/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3042 - accuracy: 0.3884 - val_loss: 1.3063 - val_accuracy: 0.3888\n",
      "Epoch 87/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3036 - accuracy: 0.3884 - val_loss: 1.3072 - val_accuracy: 0.3879\n",
      "Epoch 88/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3039 - accuracy: 0.3884 - val_loss: 1.3075 - val_accuracy: 0.3890\n",
      "Epoch 89/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3039 - accuracy: 0.3886 - val_loss: 1.3080 - val_accuracy: 0.3878\n",
      "Epoch 90/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3041 - accuracy: 0.3888 - val_loss: 1.3197 - val_accuracy: 0.3855\n",
      "Epoch 91/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3040 - accuracy: 0.3886 - val_loss: 1.3106 - val_accuracy: 0.3872\n",
      "Epoch 92/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3042 - accuracy: 0.3885 - val_loss: 1.3074 - val_accuracy: 0.3880\n",
      "Epoch 93/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3034 - accuracy: 0.3888 - val_loss: 1.3068 - val_accuracy: 0.3874\n",
      "Epoch 94/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3039 - accuracy: 0.3888 - val_loss: 1.3069 - val_accuracy: 0.3879\n",
      "Epoch 95/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3039 - accuracy: 0.3889 - val_loss: 1.3107 - val_accuracy: 0.3864\n",
      "Epoch 96/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3035 - accuracy: 0.3888 - val_loss: 1.3099 - val_accuracy: 0.3869\n",
      "Epoch 97/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3030 - accuracy: 0.3890 - val_loss: 1.3092 - val_accuracy: 0.3882\n",
      "Epoch 98/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3034 - accuracy: 0.3888 - val_loss: 1.3089 - val_accuracy: 0.3880\n",
      "Epoch 99/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3056 - accuracy: 0.3885 - val_loss: 1.3071 - val_accuracy: 0.3872\n",
      "Epoch 100/100\n",
      "5114/5114 [==============================] - 9s 2ms/step - loss: 1.3026 - accuracy: 0.3891 - val_loss: 1.3053 - val_accuracy: 0.3887\n",
      "INFO:tensorflow:Assets written to: .\\auto_model\\best_model\\assets\n",
      "40910/40910 [==============================] - 40s 960us/step\n",
      "58443/58443 [==============================] - 56s 952us/step\n",
      "17533/17533 [==============================] - 17s 958us/step\n",
      "INFO:tensorflow:Assets written to: model_autokeras_dec_class\\assets\n"
     ]
    }
   ],
   "source": [
    "# Autokeras\n",
    "model = ak.AutoModel(\n",
    "    inputs=[ak.StructuredDataInput()],\n",
    "    outputs=[ak.ClassificationHead()],\n",
    "    max_trials=5,\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=X_train_arr, y=y_train, epochs=100, batch_size=128, validation_data= [X_val_arr, y_val]\n",
    ")\n",
    "\n",
    "\n",
    "res_train_ak = model.predict(X_train_arr)\n",
    "res_test_ak = model.predict(X_test_arr)\n",
    "res_val_ak = model.predict(X_val_arr)\n",
    "\n",
    "\n",
    "model = model.export_model()\n",
    "\n",
    "\n",
    "try:\n",
    "    model.save(\"model_autokeras_dec_class\", save_format=\"tf\")\n",
    "except Exception:\n",
    "    model.save(\"model_autokeras_dec_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(classifier,x_train_dt,x_test_dt,y_train_dt,y_test_dt):\n",
    "    baseline=classifier\n",
    "    baseline.fit(x_train_dt,y_train_dt)\n",
    "    stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    pred=baseline.predict(x_test_dt)\n",
    "    print('CV score with default parameters:{}'.format(cross_val_score(classifier,x_train_dt, y_train_dt, cv=stratified_10_fold_cv, scoring='accuracy').mean()))\n",
    "    print('classification_report on test set with default parameters:\\n')\n",
    "    print(classification_report(y_test_dt,pred))\n",
    "    # cnf_matrix = confusion_matrix(y_test_dt,pred)    \n",
    "    #np.set_printoptions(precision=2)\n",
    "   # plot_confusion_matrix(cnf_matrix,classes=labels,title='confusion matrix:default')\n",
    "    return baseline\n",
    "\n",
    "\n",
    "def naivebayes (x_train,x_test,y_train,y_test):\n",
    "    gnb=GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    accuracy=cross_val_score(gnb,x_train,y_train,cv=cv)\n",
    "    print('Mean CV score is: {}'.format(accuracy.mean()))\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "    grid_search = GridSearchCV( estimator=gnb,param_grid=params_NB, cv=cv,verbose=1, scoring='accuracy') \n",
    "    grid_search.fit(x_train, y_train)\n",
    "    print(\"The best parameter is:{}\".format(grid_search.best_params_))\n",
    "    print(\"The best validation score is:{}\".format(grid_search.best_score_))\n",
    "    gnb.set_params(var_smoothing=grid_search.best_params_)\n",
    "    prediction = gnb.predict(x_test)\n",
    "    print(classification_report(y_test, prediction))\n",
    "    cm=confusion_matrix(y_test,prediction)    \n",
    "    \n",
    "    return gnb\n",
    "\n",
    "def decisionTree(x_train,x_test,y_train,y_test):\n",
    "    \n",
    "    parameters={\n",
    "            'criterion':['gini','entropy'],\n",
    "            'max_depth':[2,3,4,5,6,7,8]\n",
    "            }\n",
    "    dtree=DecisionTreeClassifier()\n",
    "    stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    grid_search=GridSearchCV(dtree,parameters,scoring='accuracy',cv=stratified_10_fold_cv)\n",
    "    grid_search.fit(x_train,y_train) \n",
    "    print('CV score with best parameters:{}'.format(cross_val_score(grid_search.best_estimator_,x_train, y_train, cv=stratified_10_fold_cv, scoring='accuracy').mean()))\n",
    "    print('best parameters:{}'.format(grid_search.best_params_))\n",
    "    pred=grid_search.predict(x_test)\n",
    "    print('classification_report with best parameters:\\n')\n",
    "    print(classification_report(y_test,pred))\n",
    "    #confusion matrix\n",
    "    dt_cnf_matrix = confusion_matrix(y_test,pred)    \n",
    "    np.set_printoptions(precision=2)    \n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def KNN(x_train,x_test,y_train,y_test):\n",
    "    \n",
    "    parameters={\n",
    "           'n_neighbors' : list(range(1,30)),\n",
    "        'p': [1,2],\n",
    "        'weights' : [\"uniform\", \"distance\"]\n",
    "            }\n",
    "    knn_2 = KNeighborsClassifier()\n",
    "    stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    Grid_search_knn = GridSearchCV(knn_2, parameters, cv=stratified_10_fold_cv)\n",
    "    best_model = Grid_search_knn.fit(x_test,y_test)\n",
    "    #Print The value of best Hyperparameters\n",
    "    cv_score=cross_val_score(Grid_search_knn.best_estimator_,x_train, y_train, cv=stratified_10_fold_cv, scoring='accuracy').mean()\n",
    "    print(\"Mean CV score is {} with params {}\".format(cv_score, Grid_search_knn.best_params_))\n",
    "    pred=Grid_search_knn.predict(x_test)\n",
    "    #print('classification_report on test set with best parameters:\\n')\n",
    "   # print(classification_report(y_test,pred))\n",
    "  \n",
    "    np.set_printoptions(precision=2)\n",
    "   \n",
    "    return Grid_search_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score with default parameters:0.24636874096128952\n",
      "classification_report on test set with default parameters:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.17      0.25    112270\n",
      "           1       0.24      0.39      0.30    111606\n",
      "           2       0.23      0.11      0.15    112657\n",
      "           3       0.23      0.27      0.25    112257\n",
      "           4       0.21      0.29      0.24    112261\n",
      "\n",
      "    accuracy                           0.25    561051\n",
      "   macro avg       0.28      0.25      0.24    561051\n",
      "weighted avg       0.28      0.25      0.24    561051\n",
      "\n",
      "\n",
      "----------after hyperparameter tuning----------\n",
      "\n",
      "Mean CV score is: 0.24636874096128952\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "The best parameter is:{'var_smoothing': 8.111308307896873e-08}\n",
      "The best validation score is:0.2605828812471506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.17      0.25    112270\n",
      "           1       0.24      0.39      0.30    111606\n",
      "           2       0.23      0.11      0.15    112657\n",
      "           3       0.23      0.27      0.25    112257\n",
      "           4       0.21      0.29      0.24    112261\n",
      "\n",
      "    accuracy                           0.25    561051\n",
      "   macro avg       0.28      0.25      0.24    561051\n",
      "weighted avg       0.28      0.25      0.24    561051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_gnb = baseline(GaussianNB(),X_train_arr,X_val_arr,y_train_n,y_val_n)\n",
    "print('\\n----------after hyperparameter tuning----------\\n')\n",
    "#model_gnb = naivebayes(X_train_arr,X_val_arr,y_train_n,y_val_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score with default parameters:0.9155844501945835\n",
      "classification_report on test set with default parameters:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94    112270\n",
      "           1       0.94      0.95      0.95    111606\n",
      "           2       0.91      0.92      0.91    112657\n",
      "           3       0.89      0.89      0.89    112257\n",
      "           4       0.90      0.89      0.90    112261\n",
      "\n",
      "    accuracy                           0.92    561051\n",
      "   macro avg       0.92      0.92      0.92    561051\n",
      "weighted avg       0.92      0.92      0.92    561051\n",
      "\n",
      "\n",
      "----------after hyperparameter tuning----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_dt = baseline(DecisionTreeClassifier(),X_train_arr,X_val_arr,y_train_n,y_val_n)\n",
    "print('\\n----------after hyperparameter tuning----------\\n')\n",
    "#model_dt = decisionTree(X_train_arr,X_val_arr,y_train_n,y_val_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_knn = baseline(KNeighborsClassifier(),X_train_arr,X_val_arr,y_train_n,y_val_n)\n",
    "#print('\\n----------after hyperparameter tuning----------\\n')\n",
    "#model_knn = KNN(X_train_arr,X_val_arr,y_train_n,y_val_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_gnb, open(\"model_gnb\", 'wb'))\n",
    "pickle.dump(model_dt, open(\"model_dt\", 'wb'))\n",
    "#pickle.dump(model_knn, open(\"model_knn\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Calculate\")\n",
    "\n",
    "res_ak = model.predict(X_test_arr)\n",
    "res_gnb = model_gnb.predict(X_test_arr)\n",
    "res_dt = model_dt.predict(X_test_arr)\n",
    "\n",
    "Stacking_set = pd.DataFrame()\n",
    "Stacking_set[\"res_ak\"] = binarizer.inverse_transform(res_ak)\n",
    "Stacking_set[\"res_gnb\"] = res_gnb\n",
    "Stacking_set[\"res_dt\"] = res_dt\n",
    "Stacking_set[\"label\"] = binarizer.inverse_transform(y_test)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res_ak</th>\n",
       "      <th>res_gnb</th>\n",
       "      <th>res_dt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870165</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870167</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870168</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1870170 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         res_ak  res_gnb  res_dt  label\n",
       "0             1        1       3      3\n",
       "1             1        4       4      3\n",
       "2             1        4       4      4\n",
       "3             0        1       1      1\n",
       "4             1        3       4      4\n",
       "...         ...      ...     ...    ...\n",
       "1870165       0        1       0      0\n",
       "1870166       0        0       0      0\n",
       "1870167       2        1       2      4\n",
       "1870168       1        2       3      3\n",
       "1870169       0        0       0      0\n",
       "\n",
       "[1870170 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stacking_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_y = binarizer.transform(Stacking_set[\"label\"])\n",
    "Stacking_x = Stacking_set.copy()\n",
    "Stacking_x = Stacking_x.drop([\"label\"], axis = 1)\n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(Stacking_x, stacking_y, test_size=0.3, random_state=42)\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 06m 31s]\n",
      "val_loss: 0.36738893389701843\n",
      "\n",
      "Best val_loss So Far: 0.36738893389701843\n",
      "Total elapsed time: 00h 06m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.6493 - accuracy: 0.8372 - val_loss: 0.3935 - val_accuracy: 0.9193\n",
      "Epoch 2/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.5237 - accuracy: 0.8783 - val_loss: 0.3800 - val_accuracy: 0.9197\n",
      "Epoch 3/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.5064 - accuracy: 0.8857 - val_loss: 0.3746 - val_accuracy: 0.9198\n",
      "Epoch 4/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.5011 - accuracy: 0.8877 - val_loss: 0.3758 - val_accuracy: 0.9198\n",
      "Epoch 5/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4995 - accuracy: 0.8898 - val_loss: 0.3720 - val_accuracy: 0.9198\n",
      "Epoch 6/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4975 - accuracy: 0.8916 - val_loss: 0.3737 - val_accuracy: 0.9198\n",
      "Epoch 7/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4962 - accuracy: 0.8932 - val_loss: 0.3706 - val_accuracy: 0.9198\n",
      "Epoch 8/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4938 - accuracy: 0.8935 - val_loss: 0.3695 - val_accuracy: 0.9198\n",
      "Epoch 9/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4928 - accuracy: 0.8938 - val_loss: 0.3697 - val_accuracy: 0.9198\n",
      "Epoch 10/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4933 - accuracy: 0.8940 - val_loss: 0.3694 - val_accuracy: 0.9198\n",
      "Epoch 11/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4917 - accuracy: 0.8943 - val_loss: 0.3682 - val_accuracy: 0.9198\n",
      "Epoch 12/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4925 - accuracy: 0.8939 - val_loss: 0.3694 - val_accuracy: 0.9198\n",
      "Epoch 13/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4918 - accuracy: 0.8938 - val_loss: 0.3690 - val_accuracy: 0.9197\n",
      "Epoch 14/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4913 - accuracy: 0.8940 - val_loss: 0.3669 - val_accuracy: 0.9197\n",
      "Epoch 15/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4909 - accuracy: 0.8941 - val_loss: 0.3667 - val_accuracy: 0.9198\n",
      "Epoch 16/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4898 - accuracy: 0.8945 - val_loss: 0.3675 - val_accuracy: 0.9197\n",
      "Epoch 17/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4894 - accuracy: 0.8945 - val_loss: 0.3676 - val_accuracy: 0.9198\n",
      "Epoch 18/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4895 - accuracy: 0.8947 - val_loss: 0.3677 - val_accuracy: 0.9197\n",
      "Epoch 19/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4888 - accuracy: 0.8957 - val_loss: 0.3672 - val_accuracy: 0.9197\n",
      "Epoch 20/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4887 - accuracy: 0.8975 - val_loss: 0.3670 - val_accuracy: 0.9198\n",
      "Epoch 21/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4819 - accuracy: 0.8996 - val_loss: 0.3672 - val_accuracy: 0.9197\n",
      "Epoch 22/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4817 - accuracy: 0.8999 - val_loss: 0.3678 - val_accuracy: 0.9191\n",
      "Epoch 23/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4821 - accuracy: 0.8994 - val_loss: 0.3676 - val_accuracy: 0.9197\n",
      "Epoch 24/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4810 - accuracy: 0.8999 - val_loss: 0.3675 - val_accuracy: 0.9195\n",
      "Epoch 25/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4770 - accuracy: 0.8998 - val_loss: 0.3671 - val_accuracy: 0.9197\n",
      "Epoch 26/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4737 - accuracy: 0.9006 - val_loss: 0.3677 - val_accuracy: 0.9191\n",
      "Epoch 27/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4729 - accuracy: 0.9012 - val_loss: 0.3666 - val_accuracy: 0.9198\n",
      "Epoch 28/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4717 - accuracy: 0.9013 - val_loss: 0.3669 - val_accuracy: 0.9198\n",
      "Epoch 29/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4724 - accuracy: 0.9011 - val_loss: 0.3653 - val_accuracy: 0.9198\n",
      "Epoch 30/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4723 - accuracy: 0.9011 - val_loss: 0.3667 - val_accuracy: 0.9197\n",
      "Epoch 31/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4730 - accuracy: 0.9010 - val_loss: 0.3663 - val_accuracy: 0.9197\n",
      "Epoch 32/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4717 - accuracy: 0.9011 - val_loss: 0.3676 - val_accuracy: 0.9198\n",
      "Epoch 33/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4694 - accuracy: 0.9024 - val_loss: 0.3672 - val_accuracy: 0.9197\n",
      "Epoch 34/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4669 - accuracy: 0.9032 - val_loss: 0.3661 - val_accuracy: 0.9197\n",
      "Epoch 35/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4672 - accuracy: 0.9032 - val_loss: 0.3666 - val_accuracy: 0.9198\n",
      "Epoch 36/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4669 - accuracy: 0.9031 - val_loss: 0.3672 - val_accuracy: 0.9198\n",
      "Epoch 37/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4672 - accuracy: 0.9030 - val_loss: 0.3675 - val_accuracy: 0.9197\n",
      "Epoch 38/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4671 - accuracy: 0.9030 - val_loss: 0.3678 - val_accuracy: 0.9197\n",
      "Epoch 39/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4675 - accuracy: 0.9032 - val_loss: 0.3672 - val_accuracy: 0.9191\n",
      "Epoch 40/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4661 - accuracy: 0.9033 - val_loss: 0.3652 - val_accuracy: 0.9198\n",
      "Epoch 41/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4671 - accuracy: 0.9031 - val_loss: 0.3656 - val_accuracy: 0.9198\n",
      "Epoch 42/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4663 - accuracy: 0.9031 - val_loss: 0.3664 - val_accuracy: 0.9191\n",
      "Epoch 43/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4662 - accuracy: 0.9032 - val_loss: 0.3660 - val_accuracy: 0.9197\n",
      "Epoch 44/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4666 - accuracy: 0.9033 - val_loss: 0.3676 - val_accuracy: 0.9198\n",
      "Epoch 45/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4667 - accuracy: 0.9031 - val_loss: 0.3677 - val_accuracy: 0.9197\n",
      "Epoch 46/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4675 - accuracy: 0.9029 - val_loss: 0.3683 - val_accuracy: 0.9198\n",
      "Epoch 47/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4665 - accuracy: 0.9031 - val_loss: 0.3662 - val_accuracy: 0.9198\n",
      "Epoch 48/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4666 - accuracy: 0.9030 - val_loss: 0.3665 - val_accuracy: 0.9195\n",
      "Epoch 49/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4666 - accuracy: 0.9033 - val_loss: 0.3679 - val_accuracy: 0.9197\n",
      "Epoch 50/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4664 - accuracy: 0.9030 - val_loss: 0.3690 - val_accuracy: 0.9191\n",
      "Epoch 51/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4664 - accuracy: 0.9031 - val_loss: 0.3676 - val_accuracy: 0.9195\n",
      "Epoch 52/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4664 - accuracy: 0.9032 - val_loss: 0.3671 - val_accuracy: 0.9197\n",
      "Epoch 53/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4668 - accuracy: 0.9033 - val_loss: 0.3673 - val_accuracy: 0.9198\n",
      "Epoch 54/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4664 - accuracy: 0.9033 - val_loss: 0.3660 - val_accuracy: 0.9198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4661 - accuracy: 0.9032 - val_loss: 0.3680 - val_accuracy: 0.9197\n",
      "Epoch 56/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4662 - accuracy: 0.9031 - val_loss: 0.3681 - val_accuracy: 0.9197\n",
      "Epoch 57/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4666 - accuracy: 0.9030 - val_loss: 0.3659 - val_accuracy: 0.9195\n",
      "Epoch 58/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4672 - accuracy: 0.9032 - val_loss: 0.3680 - val_accuracy: 0.9198\n",
      "Epoch 59/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4659 - accuracy: 0.9032 - val_loss: 0.3673 - val_accuracy: 0.9197\n",
      "Epoch 60/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4660 - accuracy: 0.9032 - val_loss: 0.3682 - val_accuracy: 0.9191\n",
      "Epoch 61/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4666 - accuracy: 0.9031 - val_loss: 0.3703 - val_accuracy: 0.9198\n",
      "Epoch 62/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4667 - accuracy: 0.9031 - val_loss: 0.3667 - val_accuracy: 0.9198\n",
      "Epoch 63/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4664 - accuracy: 0.9032 - val_loss: 0.3690 - val_accuracy: 0.9198\n",
      "Epoch 64/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4661 - accuracy: 0.9033 - val_loss: 0.3675 - val_accuracy: 0.9197\n",
      "Epoch 65/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4666 - accuracy: 0.9030 - val_loss: 0.3671 - val_accuracy: 0.9197\n",
      "Epoch 66/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4668 - accuracy: 0.9031 - val_loss: 0.3671 - val_accuracy: 0.9197\n",
      "Epoch 67/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4662 - accuracy: 0.9031 - val_loss: 0.3666 - val_accuracy: 0.9197\n",
      "Epoch 68/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4663 - accuracy: 0.9033 - val_loss: 0.3688 - val_accuracy: 0.9197\n",
      "Epoch 69/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4661 - accuracy: 0.9033 - val_loss: 0.3666 - val_accuracy: 0.9197\n",
      "Epoch 70/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4663 - accuracy: 0.9031 - val_loss: 0.3657 - val_accuracy: 0.9197\n",
      "Epoch 71/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4661 - accuracy: 0.9032 - val_loss: 0.3668 - val_accuracy: 0.9191\n",
      "Epoch 72/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4656 - accuracy: 0.9033 - val_loss: 0.3668 - val_accuracy: 0.9197\n",
      "Epoch 73/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4674 - accuracy: 0.9030 - val_loss: 0.3665 - val_accuracy: 0.9198\n",
      "Epoch 74/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4667 - accuracy: 0.9033 - val_loss: 0.3682 - val_accuracy: 0.9198\n",
      "Epoch 75/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4660 - accuracy: 0.9030 - val_loss: 0.3692 - val_accuracy: 0.9198\n",
      "Epoch 76/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4665 - accuracy: 0.9032 - val_loss: 0.3666 - val_accuracy: 0.9198\n",
      "Epoch 77/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4658 - accuracy: 0.9033 - val_loss: 0.3682 - val_accuracy: 0.9197\n",
      "Epoch 78/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4664 - accuracy: 0.9032 - val_loss: 0.3671 - val_accuracy: 0.9197\n",
      "Epoch 79/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4658 - accuracy: 0.9033 - val_loss: 0.3668 - val_accuracy: 0.9198\n",
      "Epoch 80/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4658 - accuracy: 0.9034 - val_loss: 0.3660 - val_accuracy: 0.9198\n",
      "Epoch 81/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4651 - accuracy: 0.9033 - val_loss: 0.3671 - val_accuracy: 0.9198\n",
      "Epoch 82/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4667 - accuracy: 0.9031 - val_loss: 0.3658 - val_accuracy: 0.9198\n",
      "Epoch 83/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4653 - accuracy: 0.9035 - val_loss: 0.3682 - val_accuracy: 0.9197\n",
      "Epoch 84/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4645 - accuracy: 0.9033 - val_loss: 0.3675 - val_accuracy: 0.9198\n",
      "Epoch 85/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4641 - accuracy: 0.9033 - val_loss: 0.3670 - val_accuracy: 0.9198\n",
      "Epoch 86/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4654 - accuracy: 0.9032 - val_loss: 0.3668 - val_accuracy: 0.9197\n",
      "Epoch 87/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4642 - accuracy: 0.9033 - val_loss: 0.3675 - val_accuracy: 0.9198\n",
      "Epoch 88/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4644 - accuracy: 0.9032 - val_loss: 0.3681 - val_accuracy: 0.9197\n",
      "Epoch 89/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4643 - accuracy: 0.9034 - val_loss: 0.3667 - val_accuracy: 0.9198\n",
      "Epoch 90/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4643 - accuracy: 0.9031 - val_loss: 0.3668 - val_accuracy: 0.9197\n",
      "Epoch 91/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4641 - accuracy: 0.9032 - val_loss: 0.3674 - val_accuracy: 0.9198\n",
      "Epoch 92/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4646 - accuracy: 0.9032 - val_loss: 0.3667 - val_accuracy: 0.9198\n",
      "Epoch 93/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4643 - accuracy: 0.9033 - val_loss: 0.3681 - val_accuracy: 0.9197\n",
      "Epoch 94/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4642 - accuracy: 0.9034 - val_loss: 0.3678 - val_accuracy: 0.9197\n",
      "Epoch 95/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4640 - accuracy: 0.9032 - val_loss: 0.3675 - val_accuracy: 0.9197\n",
      "Epoch 96/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4650 - accuracy: 0.9030 - val_loss: 0.3681 - val_accuracy: 0.9197\n",
      "Epoch 97/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4644 - accuracy: 0.9031 - val_loss: 0.3687 - val_accuracy: 0.9198\n",
      "Epoch 98/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4647 - accuracy: 0.9033 - val_loss: 0.3661 - val_accuracy: 0.9195\n",
      "Epoch 99/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4652 - accuracy: 0.9029 - val_loss: 0.3694 - val_accuracy: 0.9198\n",
      "Epoch 100/100\n",
      "10228/10228 [==============================] - 12s 1ms/step - loss: 0.4638 - accuracy: 0.9032 - val_loss: 0.3666 - val_accuracy: 0.9198\n",
      "INFO:tensorflow:Assets written to: .\\auto_model\\best_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6b73deb20>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final = ak.AutoModel(\n",
    "    inputs=[ak.StructuredDataInput()],\n",
    "    outputs=[ak.ClassificationHead()],\n",
    "    max_trials=1,\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "model_final.fit(\n",
    "    x=X_train, y=y_train, epochs=100, batch_size=128, validation_data= [X_val, y_val]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_final_dec\\assets\n"
     ]
    }
   ],
   "source": [
    "model_final = model_final.export_model()\n",
    "\n",
    "\n",
    "try:\n",
    "    model_final.save(\"model_final_dec\", save_format=\"tf\")\n",
    "except Exception:\n",
    "    model_final.save(\"model_final_dec.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, ..., 1, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer.inverse_transform(model_final.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, ..., 1, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer.inverse_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knabp_000\\anaconda3\\envs\\Envi\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\knabp_000\\anaconda3\\envs\\Envi\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculate\")\n",
    "\n",
    "res_ak = model.predict(submission)\n",
    "res_gnb = model_gnb.predict(submission)\n",
    "res_dt = model_dt.predict(submission)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"res_ak\"] = binarizer.inverse_transform(res_ak)\n",
    "sub[\"res_gnb\"] = res_gnb\n",
    "sub[\"res_dt\"] = res_dt\n",
    "final_res = model_final.predict(sub.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = binarizer.inverse_transform(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23363</td>\n",
       "      <td>20664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>46049</td>\n",
       "      <td>17984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>46069</td>\n",
       "      <td>29992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9742</th>\n",
       "      <td>46117</td>\n",
       "      <td>8847</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9743</th>\n",
       "      <td>46124</td>\n",
       "      <td>19677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>46127</td>\n",
       "      <td>7963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9745 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  itemID  prediction\n",
       "0          0   20664           0\n",
       "1      23363   20664           0\n",
       "2          0   28231           0\n",
       "3         13    2690           0\n",
       "4         15    1299           0\n",
       "...      ...     ...         ...\n",
       "9740   46049   17984           0\n",
       "9741   46069   29992           0\n",
       "9742   46117    8847           4\n",
       "9743   46124   19677           0\n",
       "9744   46127    7963           0\n",
       "\n",
       "[9745 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.DataFrame()\n",
    "df_submission[\"userID\"] = submission[\"userID\"]\n",
    "df_submission[\"itemID\"] = submission[\"itemID\"]\n",
    "df_submission[\"prediction\"] = final_res\n",
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'submission_dec'\n",
    "\n",
    "df_submission.to_csv(name+\"_stacking.csv\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_submission[\"prediction\"].hist(bins=5,color='blue' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envi",
   "language": "python",
   "name": "envi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
